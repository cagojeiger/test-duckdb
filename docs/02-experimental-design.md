# DuckDB 텍스트 벡터 검색 실험 설계

## 실험 목표

Python 기반 DuckDB VSS 확장을 활용한 텍스트 벡터 검색의 성능 특성을 체계적으로 분석하고 벤치마킹하여, 다양한 데이터 규모와 검색 조건에서의 최적 성능 파라미터를 도출합니다.

## 실험 변수 설계

### 1. 데이터 크기 (3가지)
- **소규모**: 10,000 벡터 (~40MB)
- **중규모**: 100,000 벡터 (~400MB)
- **대규모**: 250,000 벡터 (~1GB)

*각 벡터를 1024차원 FLOAT32 기준으로 계산 (1024 × 4바이트 = 4KB/벡터)*

### 2. 벡터 차원 (4가지)
- **128차원**: 경량 임베딩 모델 시뮬레이션
- **256차원**: 중간 성능 임베딩 모델
- **512차원**: 고성능 임베딩 모델
- **1024차원**: 최고 성능 임베딩 모델

### 3. 검색 유형 (2가지)
- **순수 벡터 검색**: VSS 확장만 사용
- **하이브리드 검색**: 벡터 + BM25 텍스트 검색 조합

### 4. 필터 조건 (2가지)
- **필터 없음**: 전체 데이터셋 대상 검색
- **필터 적용**: 메타데이터 조건 (카테고리, 날짜 등) 적용 후 검색

## 실험 조합 계산

**총 실험 조합**: 3 (데이터 크기) × 4 (벡터 차원) × 2 (검색 유형) × 2 (필터 조건) = **48가지 조합**

## 성능 측정 영역 (5가지)

### 1. 벌크 데이터 업로드 성능
- **측정 지표**: 초당 삽입 벡터 수 (vectors/sec)
- **측정 방법**: `INSERT INTO` 배치 크기별 성능 비교
- **배치 크기**: 100, 1000, 10000 벡터 단위

### 2. HNSW 인덱스 구축 성능
- **측정 지표**: 인덱스 구축 시간 (초)
- **HNSW 파라미터 조합**:
  - `ef_construction`: 64, 128, 256
  - `M`: 8, 16, 32
- **측정 방법**: `CREATE INDEX` 실행 시간

### 3. 벡터 검색 성능
- **측정 지표**:
  - 쿼리 응답 시간 (ms)
  - 처리량 (QPS - Queries Per Second)
  - 정확도 (Recall@K, K=1,5,10)
- **검색 패턴**: Top-K 검색 (K=1,5,10,50)

### 4. 하이브리드 검색 성능 (벡터 + BM25)
- **측정 지표**:
  - 하이브리드 쿼리 응답 시간
  - 순수 벡터 검색 대비 성능 비교
  - 검색 품질 향상도
- **가중치 조합**: 벡터:텍스트 = 0.7:0.3, 0.5:0.5, 0.3:0.7

### 5. 필터링 검색 성능
- **측정 지표**:
  - 필터 적용 후 검색 시간
  - 필터 선택도별 성능 변화 (1%, 10%, 50% 데이터 필터링)
- **필터 유형**: 카테고리, 날짜 범위, 수치 범위

## 총 성능 데이터 포인트

**48개 실험 조합** × **5개 성능 영역** = **240개 기본 데이터 포인트**

추가 세부 측정:
- HNSW 파라미터 조합: 3×3 = 9가지
- 배치 크기 테스트: 3가지
- Top-K 변화: 4가지
- 하이브리드 가중치: 3가지
- 필터 선택도: 3가지

**예상 총 데이터 포인트**: 약 **500-600개**

## 데이터 생성 전략

### Faker 기반 한국어 텍스트 생성
```python
from faker import Faker
fake = Faker('ko_KR')

# 텍스트 도메인별 생성
domains = {
    'news': fake.text(max_nb_chars=500),
    'reviews': fake.sentence() + " " + fake.text(max_nb_chars=200),
    'documents': fake.paragraph(nb_sentences=10)
}
```

### 메타데이터 생성
- **카테고리**: 뉴스, 리뷰, 문서, 블로그 (4가지)
- **날짜**: 2020-2025년 범위
- **길이**: 50-1000 문자
- **언어**: 한국어 (ko_KR 로케일)

### 벡터 임베딩 시뮬레이션
```python
import numpy as np

def generate_text_embedding(text: str, dimension: int) -> List[float]:
    # 텍스트 해시 기반 결정적 벡터 생성
    # 실제 임베딩 모델 없이 일관된 벡터 생성
    np.random.seed(hash(text) % 2**32)
    return np.random.normal(0, 1, dimension).astype(np.float32).tolist()
```

## 실험 실행 계획

### Phase 1: 기본 성능 측정 (1-2주)
1. 소규모 데이터 (10K 벡터) 전체 조합 테스트
2. 기본 HNSW 파라미터 최적화
3. 벡터 차원별 성능 특성 파악

### Phase 2: 확장성 테스트 (2-3주)
1. 중규모/대규모 데이터 성능 측정
2. 메모리 사용량 모니터링
3. 병목 지점 식별 및 최적화

### Phase 3: 고급 기능 테스트 (1-2주)
1. 하이브리드 검색 구현 및 성능 측정
2. 필터링 검색 최적화
3. 실시간 업데이트 성능 테스트

## 성능 분석 및 시각화

### 그래프 생성 계획
1. **데이터 크기별 벌크 업로드 속도** (선 그래프)
2. **벡터 차원별 인덱싱 시간** (막대 그래프)
3. **검색 성능 히트맵** (데이터 크기 × 벡터 차원)
4. **하이브리드 vs 순수 벡터 검색 비교** (박스 플롯)
5. **필터 선택도별 성능 변화** (산점도)

### 성능 리포트 구성
- **Executive Summary**: 주요 발견사항 요약
- **Detailed Analysis**: 각 실험 영역별 상세 분석
- **Optimization Recommendations**: 최적 파라미터 권장사항
- **Scalability Assessment**: 확장성 평가 및 제한사항
- **Future Work**: 추가 실험 및 개선 방향

## 기술적 고려사항

### DuckDB VSS 확장 제약사항
- **메모리 제약**: 인덱스가 RAM에 완전 로드
- **실험적 기능**: 안정성 모니터링 필요
- **업데이트 제한**: 삭제/수정 시 성능 저하

### 하이브리드 검색 구현 방안
```sql
-- 벡터 검색 결과와 BM25 결과 조합
WITH vector_results AS (
    SELECT id, text, array_distance(embedding, query_vector) as vector_score
    FROM documents
    ORDER BY vector_score LIMIT 100
),
text_results AS (
    SELECT id, text, fts_score
    FROM documents
    WHERE text MATCH 'query_text'
)
SELECT v.id, v.text,
       (0.7 * (1 - v.vector_score)) + (0.3 * t.fts_score) as hybrid_score
FROM vector_results v
JOIN text_results t ON v.id = t.id
ORDER BY hybrid_score DESC;
```

### 성능 모니터링 도구
- **시스템 리소스**: psutil로 CPU/메모리 모니터링
- **쿼리 성능**: DuckDB EXPLAIN ANALYZE 활용
- **인덱스 상태**: VSS 확장 통계 정보 수집

## 예상 결과 및 가설

### 가설 1: 벡터 차원과 성능의 관계
- 차원 증가 시 인덱싱 시간 지수적 증가
- 검색 정확도는 512차원까지 향상, 이후 포화

### 가설 2: 데이터 크기와 확장성
- 메모리 제약으로 인한 성능 급격한 저하 지점 존재
- 100K 벡터 이상에서 인덱싱 시간 비선형 증가

### 가설 3: 하이브리드 검색 효과
- 순수 벡터 검색 대비 20-30% 성능 저하
- 검색 품질은 15-25% 향상

### 가설 4: 필터링 성능
- 필터 선택도 10% 이하에서 성능 최적화 효과
- 50% 이상 필터링 시 브루트포스와 유사한 성능

## 리스크 및 완화 방안

### 기술적 리스크
1. **메모리 부족**: 클라우드 인스턴스 확장 또는 데이터 크기 조정
2. **VSS 확장 불안정**: 실험 중 데이터 백업 및 복구 계획
3. **하이브리드 검색 미지원**: 대안 구현 방안 준비

### 일정 리스크
1. **실험 시간 초과**: 우선순위 기반 단계적 실행
2. **결과 분석 지연**: 자동화된 리포트 생성 도구 개발

## 성공 기준

### 정량적 기준
- 48개 실험 조합 100% 완료
- 500개 이상 성능 데이터 포인트 수집
- 5개 핵심 성능 그래프 생성

### 정성적 기준
- DuckDB VSS 확장의 실용적 사용 가이드라인 도출
- 텍스트 벡터 검색 최적화 권장사항 제시
- 확장성 제한사항 및 해결 방안 문서화
